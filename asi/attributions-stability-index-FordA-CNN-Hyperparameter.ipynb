{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1db1d7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc6bdf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import tqdm.notebook as tq\n",
    "import tqdm as tq\n",
    "\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [30, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fe5b43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 13\n",
    "\n",
    "torch.manual_seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b9f4f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'FordA'\n",
    "\n",
    "from sktime.datasets import load_UCR_UEA_dataset\n",
    "\n",
    "X_train, y_train = load_UCR_UEA_dataset(name=dataset, split='train', return_type='numpyflat')\n",
    "X_test, y_test = load_UCR_UEA_dataset(name=dataset, split='test', return_type='numpyflat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70a11dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length training data: 3601 labels: 3601 test data: 1320 labels: 1320\n"
     ]
    }
   ],
   "source": [
    "print(f'Length training data: {len(X_train)} labels: {len(y_train)} test data: {len(X_test)} labels: {len(y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "729a380f",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(categories='auto', sparse_output=False)\n",
    "\n",
    "y_train_ohe = encoder.fit_transform(np.expand_dims(y_train, axis=-1))\n",
    "y_test_ohe = encoder.transform(np.expand_dims(y_test, axis=-1))\n",
    "\n",
    "y_train_norm = y_train_ohe.argmax(axis=-1)\n",
    "y_test_norm = y_test_ohe.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba0c9180",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FordADataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        inputs = self.X[idx]\n",
    "        label = self.y[idx]\n",
    "        \n",
    "        return inputs, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22aeaeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = FordADataset(X_train, y_train_ohe)\n",
    "dataset_test = FordADataset(X_test, y_test_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da061f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(dataset_train, batch_size=120, shuffle=True)\n",
    "dataloader_train_not_shuffled = DataLoader(dataset_train, batch_size=120, shuffle=False)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=120, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d19e8729",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 10, kernel_size=3, stride=1),\n",
    "            nn.BatchNorm1d(10),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(10, 50, kernel_size=3, stride=1),\n",
    "            nn.BatchNorm1d(50),\n",
    "            nn.MaxPool1d(3),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(50, 50, kernel_size=3, stride=1),\n",
    "            nn.BatchNorm1d(50),\n",
    "            nn.MaxPool1d(3),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(50 * 54, 50),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(50, 2),\n",
    "            nn.Softmax(-1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "\n",
    "        batch_size = x.shape[0]\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b7641e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961ef240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16bc5213",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('models/ford-a-cnn.pth')\n",
    "model.eval()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94cc7cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f691e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1dba261d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy Train 0.9889\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "preds = []\n",
    "labels = []\n",
    "for x in dataloader_train_not_shuffled:\n",
    "    input_, label_ = x\n",
    "    input_ = input_.reshape(input_.shape[0], 1, -1)\n",
    "    input_ = input_.float().to(device)\n",
    "    label_ = label_.float().to(device)\n",
    "\n",
    "    pred_ = model(input_)\n",
    "    preds.extend(pred_)\n",
    "    labels.extend(label_)\n",
    "\n",
    "preds = torch.stack(preds)\n",
    "labels = torch.stack(labels)\n",
    "print('Prediction Accuracy Train', np.round((preds.argmax(dim=-1) == labels.argmax(dim=-1)).int().sum().float().item() / len(preds), 4))\n",
    "\n",
    "y_train_pred = preds.cpu().detach().numpy().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df0c6f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction Accuracy Test 0.9121\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "preds = []\n",
    "labels = []\n",
    "for x in dataloader_test:\n",
    "    input_, label_ = x\n",
    "    input_ = input_.reshape(input_.shape[0], 1, -1)\n",
    "    input_ = input_.float().to(device)\n",
    "    label_ = label_.float().to(device)\n",
    "\n",
    "    pred_ = model(input_)\n",
    "    preds.extend(pred_)\n",
    "    labels.extend(label_)\n",
    "\n",
    "preds = torch.stack(preds)\n",
    "labels = torch.stack(labels)\n",
    "print('Prediction Accuracy Test', np.round((preds.argmax(dim=-1) == labels.argmax(dim=-1)).int().sum().float().item() / len(preds), 4))\n",
    "\n",
    "y_test_pred = preds.cpu().detach().numpy().round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e702cc",
   "metadata": {},
   "source": [
    "# Save results as json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77c66d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa6390ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import exp_perturbation_analysis as exp_pa\n",
    "\n",
    "import exp_stability_indicator as exp_si\n",
    "\n",
    "import exp_plots as exp_pl\n",
    "\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d37b195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import GradientShap, DeepLiftShap, IntegratedGradients, ShapleyValueSampling, Saliency, DeepLift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5e3b889",
   "metadata": {},
   "outputs": [],
   "source": [
    "attribution_measure = exp_si.attribution_stability_indicator\n",
    "get_asi_for_dataset = exp_si.get_asi_for_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ad659a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 2\n",
    "sample_ts_np, sample_l = dataloader_test.dataset[sample_idx]\n",
    "\n",
    "sample, label = dataset_train[0]\n",
    "shape = sample_ts_np.reshape(1, -1).shape\n",
    "\n",
    "baselines = torch.from_numpy(np.array([dataset_test[torch.randint(len(dataset_test), (1,))][0] for _ in range(10)])).reshape(-1, *shape).float().to(device)\n",
    "\n",
    "\n",
    "\n",
    "attribution_techniques = [\n",
    "    ['Saliency', Saliency, {}],\n",
    "    ['GradientShap', GradientShap, {'baselines': baselines}],\n",
    "    \n",
    "    ['DeepLift', DeepLift, {}],\n",
    "    ['DeepLiftShap', DeepLiftShap, {'baselines': baselines}],\n",
    "    \n",
    "    ['IntegratedGradients', IntegratedGradients, {}],\n",
    "    \n",
    "#     ['ShapleyValueSampling', ShapleyValueSampling, {}],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf99912b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d902ace2",
   "metadata": {},
   "source": [
    "# Check hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df15c545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "loader = dataloader_train_not_shuffled\n",
    "\n",
    "weights_to_test = ['amax', 'js', 'ts', 'att']\n",
    "weights_boundaries = [0, 3, 1]\n",
    "\n",
    "def define_weights(dimensions, boundaries):\n",
    "    low_bound, high_bound, steps = boundaries\n",
    "    scaled_steps = 1 / steps\n",
    "    high_bound = int(high_bound * scaled_steps + 1)\n",
    "    return np.array(list(product(range(low_bound, high_bound), repeat=dimensions))) / scaled_steps\n",
    "\n",
    "weights_to_test = define_weights(len(weights_to_test), weights_boundaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cd1ce27c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., 1.],\n",
       "        [0., 0., 0., 2.],\n",
       "        [0., 0., 0., 3.],\n",
       "        ...,\n",
       "        [3., 3., 3., 1.],\n",
       "        [3., 3., 3., 2.],\n",
       "        [3., 3., 3., 3.]]),\n",
       " (255, 4))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_to_test[1:,:], weights_to_test[1:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ed811cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.066666666666666"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_to_test.shape[0] * 240 / 60 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a8c3b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import json\n",
    "\n",
    "class NumpyArrayEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        if isinstance(obj, np.int64):\n",
    "            return str(obj)\n",
    "        if isinstance(obj, np.float32):\n",
    "            return str(obj)\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "    \n",
    "def checkpoint_save(file_name, data):\n",
    "    if os.path.exists(file_name):\n",
    "        with open(f'{file_name}', 'r+') as f:\n",
    "            old_data = json.load(f)\n",
    "    else:\n",
    "        old_data = []\n",
    "    old_data += data\n",
    "    old_data_json = json.dumps(old_data, cls=NumpyArrayEncoder)\n",
    "    with open(f'{file_name}', 'w+') as f:\n",
    "        f.write(old_data_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca25f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/schlegel/.conda/captum/lib/python3.10/site-packages/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n",
      "44it [7:24:19, 604.26s/it]"
     ]
    }
   ],
   "source": [
    "file_name = 'results/ford-a-cnn-results'\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, w_to_test in tq.tqdm(enumerate(weights_to_test[1:,:])):\n",
    "    ret_dict = get_asi_for_dataset(loader, model, attribution_techniques, w_to_test, no_bar=True, full_dict=False)\n",
    "    if i % 50 == 0:\n",
    "        checkpoint_save(f'{file_name}.json', results)\n",
    "        results = []\n",
    "    results.append([i, w_to_test, ret_dict])\n",
    "checkpoint_save(f'{file_name}.json', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5df462",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Captum",
   "language": "python",
   "name": "captum"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
